# CP-001: Data Model & Identity

> **Spec Version**: 1.0.0
> **Author**: Nadeem Bhati
> **Category**: Core
> **Requires**: None

## Synopsis

This specification defines the canonical data types that comprise the CP substrate. All CP implementations MUST support these data types with the exact semantics described herein.

## Motivation

A well-defined data model is essential for:

1. **Interoperability**: Different implementations can exchange data
2. **Determinism**: Identical representations produce identical hashes
3. **Auditability**: Clear semantics enable verification and debugging
4. **Extensibility**: Future versions can add fields without breaking compatibility

## Technical Specification

### 1. Identity Primitives

CP uses a unified 128-bit identity schema derived from content hashes.

**Type Definition**:
```rust
type ID = [u8; 16];  // 128-bit identifier
```

**Generation Algorithm**:

IDs are the first 16 bytes of the BLAKE3 hash of the input.

```rust
fn generate_id(input: &[u8]) -> ID {
    let hash = blake3::hash(input);
    let mut id = [0u8; 16];
    id.copy_from_slice(&hash.as_bytes()[0..16]);
    id
}
```

**Rationale**:
- **Deterministic**: Derived purely from input.
- **Fast**: Uses BLAKE3 SIMD implementation.
- **Compact**: 16 bytes fits in standard UUID fields for DB compatibility.
- **Collision Resistant**: 128-bits provides adequate collision resistance for local graphs (~3x10^38 possibilities).

### 2. Document

A **Document** represents an ingested file in the substrate.

#### Schema

```
Document {
    id:              ID          // Deterministic identifier (BLAKE3-16 of content_hash)
    path_id:         ID          // Deterministic identifier for file path (for change detection)
    path:            String      // Original filesystem path (for display/retrieval)
    content_hash:    [u8; 32]   // BLAKE3 hash of file contents
    hierarchical_hash: [u8; 32]  // BLAKE3 hash of all chunk hashes
    mtime:           i64         // Unix timestamp (milliseconds)
    size_bytes:      u64         // File size in bytes
    mime_type:       String      // MIME type (e.g., "text/markdown")
}
```

#### Identity Derivation

The Document ID is **content-based** - identical content always produces identical ID:

```
document_id = generate_id(content_hash)
```

The Path ID is **path-based** - enables tracking file moves/renames without content changes:

```
path_id = generate_id(path.as_bytes())  // Canonicalized path
```

**Rationale**:
- `id`: Enables content deduplication across different paths
- `path_id`: Enables detecting when the same path has different content (modification)

#### Hierarchical Hash

The hierarchical hash provides a Merkle commitment to all chunks belonging to this document:

```
hierarchical_hash = BLAKE3(
    sorted_chunk_hashes.join()  // Chunks sorted by sequence number
)
```

This enables verification that chunk content has not been modified.



#### Overlap Semantics

Chunks MAY overlap to preserve semantic context across boundaries:

```
Document: "The quick brown fox jumps over the lazy dog."
                                    ^^^^
                    Chunk 1 ends here ─┘└─ Chunk 2 begins here
                    (overlapping region)
```

The `byte_offset` and `byte_length` fields precisely define each chunk's extent, allowing reconstruction of overlap relationships.

### 3. Embedding

An **Embedding** represents the vector representation of a chunk.

#### Schema

```
Embedding {
    id:              ID          // Deterministic identifier (BLAKE3-16)
    chunk_id:        ID          // Source chunk reference
    vector:          [i16; N]    // Embedding vector (i16 quantization)
    model_hash:      [u8; 32]    // BLAKE3 hash of model manifest
    embedding_version: u32       // Version counter for re-embedding scenarios
    l2_norm:         i64         // Precomputed L2 norm squared (integer for determinism)
}
```

#### Identity Derivation

```
embedding_id = generate_id(chunk_id || model_hash || embedding_version.to_le_bytes())
```

#### Vector Format

Embeddings are stored in **i16 (signed 16-bit integer)** format:

- **Rationale**: Strict bit-level determinism across architectures (avoids FPU inconsistencies)
- **Precision**: Quantized from SoftFloat (range -32767 to 32767)
- **Dimension**: Implementation-defined (typically 384 for MiniLM-L6-v2)

#### Model Provenance

The `model_hash` field provides cryptographic binding to the embedding model:

```
model_hash = BLAKE3(model_identifier_string)
```

This ensures embeddings generated by different models are not conflated.

### 4. Chunk
A **Chunk** represents a semantic unit of text extracted from a document.

#### Schema
```rust
struct Chunk {
    id:              ID,         // generate_id(doc_id || sequence) - STABLE across re-chunking
    document_id:     ID,         // Parent document
    text:            String,     // Valid UTF-8 (canonicalized)
    text_hash:       [u8; 32], // BLAKE3(canonicalized_text) - for content verification
    byte_offset:     u64,        // Start position in source document
    byte_length:     u64,        // Length in bytes
    sequence:        u32,        // Order in document (0-indexed)
}
```

#### Identity Derivation
```rust
// STABLE ID: chunk identity is independent of text content
// This ensures re-chunking with different parameters doesn't change IDs
chunk_id = generate_id(
    document_id +
    sequence.to_le_bytes()
)
```

**Changes from V0**:
- **Stable Identity**: Chunk ID no longer includes text, making it stable across re-chunking operations
- **Content Verification**: `text_hash` field provides cryptographic verification of chunk content
- **Deduplication**: Chunks are **NOT** globally deduplicated. "Introduction" in Doc A is distinct from "Introduction" in Doc B. This simplifies graph edges and provenance.

### 5. Edge

An **Edge** represents a relationship between entities in the substrate.

#### Schema

```
Edge {
    source_id:       ID          // Source entity
    target_id:       ID          // Target entity
    kind:            EdgeKind    // Relationship type
    weight:          Option<f32> // Optional relationship strength
}
```

#### Edge Kinds

```
enum EdgeKind {
    DocToChunk,        // Document contains Chunk
    ChunkToEmbedding,  // Chunk has Embedding
    ChunkToChunk,      // Semantic similarity between chunks
    Custom(String),    // User-defined relationship
}
```

#### Canonicalization

Edges are uniquely identified by the tuple `(source_id, target_id, kind)`. No duplicate edges are permitted.

### 5. StateRoot

A **StateRoot** represents a cryptographic commitment to the entire substrate state.

#### Schema

```
StateRoot {
    hash:            [u8; 32]    // BLAKE3 Merkle root
    parent_hash:     Option<[u8; 32]>  // Previous state root (chain)
    timestamp:       i64         // Unix timestamp (milliseconds)
    device_id:       ID          // Originating device
    signature:       [u8; 64]    // Ed25519 signature
    sequence:        u64         // Monotonic sequence number
}
```

#### Merkle Root Computation

State roots are computed using a **binary Merkle Tree** with BLAKE3, enabling efficient proof generation and verification.

##### Algorithm

```
function compute_merkle_root(entities: Vec<Entity>) -> [u8; 32]:
    // 1. Sort entities by ID (deterministic order)
    sorted = entities.sort_by(|a, b| a.id.cmp(b.id))

    // 2. Compute leaf hashes
    leaves = sorted.map(|e| BLAKE3(e.to_canonical_bytes()))

    // 3. Build tree bottom-up (binary)
    return merkle_tree(leaves)

function merkle_tree(leaves: Vec<[u8; 32]>) -> [u8; 32]:
    if leaves.len() == 0:
        return BLAKE3(b"empty")

    if leaves.len() == 1:
        return leaves[0]

    // Pair up leaves and hash
    next_level = []
    for i in range(0, leaves.len(), 2):
        if i + 1 < leaves.len():
            // Two children: hash(left || right)
            parent = BLAKE3(leaves[i] || leaves[i+1])
        else:
            // Odd leaf: hash(leaf || leaf) - duplicate for perfect tree
            parent = BLAKE3(leaves[i] || leaves[i])
        next_level.push(parent)

    return merkle_tree(next_level)
```

##### Entity Canonical Bytes

Each entity type has a deterministic serialization for hashing:

```
// Document
doc.to_canonical_bytes():
    return id || content_hash || hierarchical_hash

// Chunk
chunk.to_canonical_bytes():
    return id || text_hash

// Embedding
emb.to_canonical_bytes():
    return id || vector_bytes || model_hash

// Edge
edge.to_canonical_bytes():
    return source_id || target_id || kind_as_byte || weight_bytes
```

##### State Root Composition

The final state root combines all entity roots:

```
function compute_state_root(
    docs: Vec<Document>,
    chunks: Vec<Chunk>,
    embeddings: Vec<Embedding>,
    edges: Vec<Edge>
) -> [u8; 32]:
    doc_root = merkle_tree(docs.map(|d| d.to_canonical_bytes()))
    chunk_root = merkle_tree(chunks.map(|c| c.to_canonical_bytes()))
    emb_root = merkle_tree(embeddings.map(|e| e.to_canonical_bytes()))
    edge_root = merkle_tree(edges.map(|e| e.to_canonical_bytes()))

    // Final composition
    return BLAKE3(doc_root || chunk_root || emb_root || edge_root)
```

##### Merkle Proofs

For partial verification (sync scenarios):

```
struct MerkleProof {
    leaf_hash: [u8; 32],
    path: Vec<MerkleNode>,  // Sibling hashes from leaf to root
    position: u64,           // Position in tree (for verification)
}

function generate_proof(entities: Vec<Entity>, target_id: ID) -> MerkleProof:
    // Returns proof that target_id exists in tree
    // Useful for sync verification without full state transfer
```

See `CP-002` logic for precise node construction.

#### State Chain

State roots form a hash chain, enabling:

1. **Lineage Verification**: Trace state evolution over time
2. **Fork Detection**: Identify divergent state branches
3. **Rollback Points**: Return to previous verified states

### 6. CognitiveDiff

A **CognitiveDiff** represents an atomic unit of state change.

#### Schema

```
CognitiveDiff {
    // Added or updated entities
    documents:       Vec<Document>
    chunks:          Vec<Chunk>
    embeddings:      Vec<Embedding>
    edges:           Vec<Edge>

    // Removed entity IDs
    removed_documents:   Vec<ID>
    removed_chunks:      Vec<ID>
    removed_embeddings:  Vec<ID>
    removed_edges:       Vec<(ID, ID, EdgeKind)>


    // Metadata
    prev_root:       [u8; 32]    // State root before diff
    new_root:        [u8; 32]    // State root after diff
    timestamp:       i64         // Creation timestamp
    device_id:       ID          // Originating device
    sequence:        u64         // Diff sequence number
}
```

#### Serialization

CognitiveDiffs are serialized using:

1. **CBOR**: Canonical Binary Object Representation (RFC 8949)
2. **zstd**: Compression for network transmission

## Desired Properties

### 1. Determinism

**Property**: Given identical inputs, any conformant implementation MUST produce identical data structures.

**Verification**:
```
∀ input: hash(process(input)) = hash(process(input))
```

### 2. Referential Integrity

**Property**: All foreign key references MUST point to existing entities.

**Constraints**:
- `Chunk.document_id` MUST reference an existing `Document`
- `Embedding.chunk_id` MUST reference an existing `Chunk`
- `Edge.source_id` and `Edge.target_id` MUST reference existing entities

### 7. Standard Schemas (Annotations)

To support user-facing features (Notes, Tags, Highlights) without bloating the core protocol, CP defines standard **Edge Kinds** and **Meta-Documents**.

#### 7.1 Tags
Tags are modeled as edges to a "Tag Document".

- **Entity**: `Document { path: "tags/productivity", ... }`
- **Edge**: `Edge { source: target_doc_id, target: tag_doc_id, kind: "TaggedWith" }`

#### 7.2 Highlights
Highlights are "Meta-Documents" that reference a specific text range in a chunk.

- **Entity**: `Document { type: "annotation/highlight", content: "selected text..." }`
- **Edge**: `Edge { source: highlight_id, target: chunk_id, kind: "Details", weight: start_offset.end_offset }`

This allows the retrieval system to treat annotations as just another form of content.

### 4. Cascade Semantics

**Property**: Deleting an entity MUST delete all dependent entities.

**Cascade Rules**:
- Deleting a `Document` deletes all its `Chunk`s
- Deleting a `Chunk` deletes all its `Embedding`s
- Deleting an entity removes all `Edge`s referencing it

## Backwards Compatibility

New fields MAY be added to data types in minor versions. Implementations MUST:

1. Ignore unknown fields when deserializing
2. Preserve unknown fields when re-serializing (round-trip safety)
3. Provide sensible defaults for missing optional fields

## Test Vectors

### Document ID Generation

```
Input:
    content_hash = 0xaf1349b9f5f9a1a6a0404dea36dcc9499bcb25c9adc112b7cc9a93cae41f3262

Expected:
    document_id = ID("a7f3b2c1-4d5e-5f6a-8b9c-0d1e2f3a4b5c")
```

### Chunk ID Generation

```
Input:
    text = "The quick brown fox jumps over the lazy dog."
    text_hash = BLAKE3(text)

Expected:
    chunk_id = ID("b8c4d3e2-5f6a-5b7c-9d0e-1f2a3b4c5d6e")
```

## References

- [BLAKE3 Specification](https://github.com/BLAKE3-team/BLAKE3-specs)
- [RFC 8949: CBOR](https://tools.ietf.org/html/rfc8949)
